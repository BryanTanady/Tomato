# M5 - Reflections

## 1. AI Reflections
AI Technology was used in the creation of the MVP.

1. Deepseek, ChatGPT, GitHub Copilot

2. The goal of using these technologies was to act as a starting point for writing and debugging code, as well as a "search engine" for documentation with responses that are tailored for the code's specific architecture and use cases.

    In the case of M5, sometimes AI was used in order to generate boilerplate code for tests, to ask and clarify how to resolve codacy issues, and debug certain parts of the code.

3. AI is advantageous as it can tailor responses very specifically to the user's demands, as compared to googling an issue where you may find similar but not necessarily same conditions or issues.

    Some positive examples included when we were unsure why a specific segment of code was generating a codacy error, so we put the code segment as well as the codacy error into the AI and we were able to determine why the error was occurring, with further prompting.

4. AI is disavantageous as it lacks a broader perspective on the wider use cases and reasoning behind the operation of the whole system. 

    Some examples where this was difficult was in implementing the end to end tests, where the AI lacks fundamental reasoning on how the users will interact with the system and what problems they might face.

5. 15%. The boilerplate code for the tests was initially generated with AI, but subsequently the tests had to be modified for a single use case, then the developer will write the rest of the tests using a similar syntax, but not generated with AI. 

## 2. Contributions of each team member
- Rumbi Chinamo: Backend API tests, added backend-test.yml, added backend api test documentation
- Bryan Tanady: 
- Xuan Tung Luu: Frontend E2E test, non-functional requirement - 16hr
- James: Rectify code styling errors on codacy, maintain backend production, ensure automation via CI/CD tools. - 15h
